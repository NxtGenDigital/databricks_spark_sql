{"cells":[{"cell_type":"markdown","source":["d-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px; height: 163px\">\n</div>"],"metadata":{}},{"cell_type":"markdown","source":["# Querying JSON & Hierarchical Data with SQL\n\nApache Spark&trade; and Databricks&reg; make it easy to work with hierarchical data, such as nested JSON records.\n\n## In this lesson you:\n* Use SQL to query a table backed by JSON data\n* Query nested structured data\n* Query data containing array columns \n\n## Audience\n* Primary Audience: Data Analysts\n* Additional Audiences: Data Engineers and Data Scientists\n\n## Prerequisites\n* Web browser: **Chrome**\n* A cluster configured with **8 cores** and **DBR 6.3**\n* Familiarity with <a href=\"https://www.w3schools.com/sql/\" target=\"_blank\">ANSI SQL</a> is required"],"metadata":{}},{"cell_type":"markdown","source":["## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Classroom-Setup & Classroom-Cleanup<br>\n\nFor each lesson to execute correctly, please make sure to run the **`Classroom-Setup`** cell at the start of each lesson (see the next cell) and the **`Classroom-Cleanup`** cell at the end of each lesson."],"metadata":{}},{"cell_type":"code","source":["%run \"./Includes/Classroom-Setup\""],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["<iframe  \nsrc=\"//fast.wistia.net/embed/iframe/a3098jg2t0?videoFoam=true\"\nstyle=\"border:1px solid #1cb1c2;\"\nallowtransparency=\"true\" scrolling=\"no\" class=\"wistia_embed\"\nname=\"wistia_embed\" allowfullscreen mozallowfullscreen webkitallowfullscreen\noallowfullscreen msallowfullscreen width=\"640\" height=\"360\" ></iframe>\n<div>\n<a target=\"_blank\" href=\"https://fast.wistia.net/embed/iframe/a3098jg2t0?seo=false\">\n  <img alt=\"Opens in new tab\" src=\"https://files.training.databricks.com/static/images/external-link-icon-16x16.png\"/>&nbsp;Watch full-screen.</a>\n</div>"],"metadata":{}},{"cell_type":"markdown","source":["## Examining the contents of a JSON file\n\nJSON is a common file format in big data applications and in data lakes (or large stores of diverse data).  Datatypes such as JSON arise out of a number of data needs.  For instance, what if...  \n<br>\n* Your schema, or the structure of your data, changes over time?\n* You need nested fields like an array with many values or an array of arrays?\n* You don't know how you're going use your data yet so you don't want to spend time creating relational tables?\n\nThe popularity of JSON is largely due to the fact that JSON allows for nested, flexible schemas.\n\nThis lesson uses the `DatabricksBlog` table, which is backed by JSON file `dbfs:/mnt/training/databricks-blog.json`. If you examine the raw file, you can see that it contains compact JSON data. There's a single JSON object on each line of the file; each object corresponds to a row in the table. Each row represents a blog post on the <a href=\"https://databricks.com/blog\" target=\"_blank\">Databricks blog</a>, and the table contains all blog posts through August 9, 2017."],"metadata":{}},{"cell_type":"markdown","source":["<iframe  \nsrc=\"//fast.wistia.net/embed/iframe/1i3n3rb0vy?videoFoam=true\"\nstyle=\"border:1px solid #1cb1c2;\"\nallowtransparency=\"true\" scrolling=\"no\" class=\"wistia_embed\"\nname=\"wistia_embed\" allowfullscreen mozallowfullscreen webkitallowfullscreen\noallowfullscreen msallowfullscreen width=\"640\" height=\"360\" ></iframe>\n<div>\n<a target=\"_blank\" href=\"https://fast.wistia.net/embed/iframe/1i3n3rb0vy?seo=false\">\n  <img alt=\"Opens in new tab\" src=\"https://files.training.databricks.com/static/images/external-link-icon-16x16.png\"/>&nbsp;Watch full-screen.</a>\n</div>"],"metadata":{}},{"cell_type":"code","source":["%fs head dbfs:/mnt/training/databricks-blog.json"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["To expose the JSON file as a table, use the standard SQL create table using syntax introduced in the previous lesson:"],"metadata":{}},{"cell_type":"code","source":["%sql\nCREATE TABLE IF NOT EXISTS DatabricksBlog\n  USING json\n  OPTIONS (\n    path \"dbfs:/mnt/training/databricks-blog.json\",\n    inferSchema \"true\"\n  )"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["Take a look at the schema with the `DESCRIBE` function."],"metadata":{}},{"cell_type":"code","source":["%sql\nDESCRIBE DatabricksBlog"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["Run a query to view the contents of the table.\n\nNotice:\n* The `authors` column is an array containing multiple author names.\n* The `categories` column is an array of multiple blog post category names.\n* The `dates` column contains nested fields `createdOn`, `publishedOn` and `tz`."],"metadata":{}},{"cell_type":"code","source":["%sql\nSELECT authors, categories, dates, content \nFROM DatabricksBlog"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":["## Nested Data\n\nThink of nested data as columns within columns. \n\nFor instance, look at the `dates` column."],"metadata":{}},{"cell_type":"markdown","source":["<iframe  \nsrc=\"//fast.wistia.net/embed/iframe/kqmfblujy9?videoFoam=true\"\nstyle=\"border:1px solid #1cb1c2;\"\nallowtransparency=\"true\" scrolling=\"no\" class=\"wistia_embed\"\nname=\"wistia_embed\" allowfullscreen mozallowfullscreen webkitallowfullscreen\noallowfullscreen msallowfullscreen width=\"640\" height=\"360\" ></iframe>\n<div>\n<a target=\"_blank\" href=\"https://fast.wistia.net/embed/iframe/kqmfblujy9?seo=false\">\n  <img alt=\"Opens in new tab\" src=\"https://files.training.databricks.com/static/images/external-link-icon-16x16.png\"/>&nbsp;Watch full-screen.</a>\n</div>"],"metadata":{}},{"cell_type":"code","source":["%sql\nSELECT dates FROM DatabricksBlog"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":["Pull out a specific subfield with \"dot\" notation."],"metadata":{}},{"cell_type":"code","source":["%sql\nSELECT dates.createdOn, dates.publishedOn \nFROM DatabricksBlog"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":["Both `createdOn` and `publishedOn` are stored as strings.\n\nCast those values to SQL timestamps:\n\nIn this case, use a single `SELECT` statement to:\n0. Cast `dates.publishedOn` to a `timestamp` data type.\n0. \"Flatten\" the `dates.publishedOn` column to just `publishedOn`."],"metadata":{}},{"cell_type":"code","source":["%sql\nSELECT title, \n       cast(dates.publishedOn AS timestamp) AS publishedOn \nFROM DatabricksBlog"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":["Create the temporary view `DatabricksBlog2` to capture the conversion and flattening of the `publishedOn` column."],"metadata":{}},{"cell_type":"code","source":["%sql\nCREATE OR REPLACE TEMPORARY VIEW DatabricksBlog2 AS\n  SELECT *, \n         cast(dates.publishedOn AS timestamp) AS publishedOn \n  FROM DatabricksBlog"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":["Now that we have this temporary view, we can use `DESCRIBE` to check its schema and confirm the timestamp conversion."],"metadata":{}},{"cell_type":"code","source":["%sql\nDESCRIBE DatabricksBlog2"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":["-sandbox\nNow the dates are represented by a `timestamp` data type, query for articles within certain date ranges (such as getting a list of all articles published in 2013), and format the date for presentation purposes.\n\n<img alt=\"Side Note\" title=\"Side Note\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.05em; transform:rotate(15deg)\" src=\"https://files.training.databricks.com/static/images/icon-note.webp\"/> See the Spark documentation, <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#module-pyspark.sql.functions\" target=\"_blank\">built-in functions</a>, for a long list of date-specific functions."],"metadata":{}},{"cell_type":"code","source":["%sql\nSELECT title, \n       date_format(publishedOn, \"MMM dd, yyyy\") AS date, \n       link \nFROM DatabricksBlog2\nWHERE year(publishedOn) = 2013\nORDER BY publishedOn"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":["## Array Data\n\nThe table also contains array columns. \n\nEasily determine the size of each array using the built-in `size(..)` function with array columns."],"metadata":{}},{"cell_type":"markdown","source":["<iframe  \nsrc=\"//fast.wistia.net/embed/iframe/w9vj8mjpf7?videoFoam=true\"\nstyle=\"border:1px solid #1cb1c2;\"\nallowtransparency=\"true\" scrolling=\"no\" class=\"wistia_embed\"\nname=\"wistia_embed\" allowfullscreen mozallowfullscreen webkitallowfullscreen\noallowfullscreen msallowfullscreen width=\"640\" height=\"360\" ></iframe>\n<div>\n<a target=\"_blank\" href=\"https://fast.wistia.net/embed/iframe/w9vj8mjpf7?seo=false\">\n  <img alt=\"Opens in new tab\" src=\"https://files.training.databricks.com/static/images/external-link-icon-16x16.png\"/>&nbsp;Watch full-screen.</a>\n</div>"],"metadata":{}},{"cell_type":"code","source":["%sql\nSELECT size(authors), \n       authors \nFROM DatabricksBlog"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"markdown","source":["Pull the first element from the array `authors` using an array subscript operator."],"metadata":{}},{"cell_type":"code","source":["%sql\nSELECT authors[0] AS primaryAuthor \nFROM DatabricksBlog"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"markdown","source":["### Explode\n\nThe `explode` function allows you to split an array column into multiple rows, copying all the other columns into each new row. \n\nFor example, you can split the column `authors` into the column `author`, with one author per row."],"metadata":{}},{"cell_type":"markdown","source":["<iframe  \nsrc=\"//fast.wistia.net/embed/iframe/h8tv263d04?videoFoam=true\"\nstyle=\"border:1px solid #1cb1c2;\"\nallowtransparency=\"true\" scrolling=\"no\" class=\"wistia_embed\"\nname=\"wistia_embed\" allowfullscreen mozallowfullscreen webkitallowfullscreen\noallowfullscreen msallowfullscreen width=\"640\" height=\"360\" ></iframe>\n<div>\n<a target=\"_blank\" href=\"https://fast.wistia.net/embed/iframe/h8tv263d04?seo=false\">\n  <img alt=\"Opens in new tab\" src=\"https://files.training.databricks.com/static/images/external-link-icon-16x16.png\"/>&nbsp;Watch full-screen.</a>\n</div>"],"metadata":{}},{"cell_type":"code","source":["%sql\nSELECT title, \n       authors, \n       explode(authors) AS author, \n       link \nFROM DatabricksBlog"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"markdown","source":["It's more obvious to restrict the output to articles that have multiple authors, and sort by the title."],"metadata":{}},{"cell_type":"code","source":["%sql\nSELECT title, \n       authors, \n       explode(authors) AS author, \n       link \nFROM DatabricksBlog \nWHERE size(authors) > 1 \nORDER BY title"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"markdown","source":["### Lateral View\nThe data has multiple columns with nested objects.  In this case, the data has multiple dates, authors, and categories.\n\nTake a look at the blog entry **Apache Spark 1.1: The State of Spark Streaming**:"],"metadata":{}},{"cell_type":"code","source":["%sql\nSELECT dates.publishedOn, title, authors, categories\nFROM DatabricksBlog\nWHERE title = \"Apache Spark 1.1: The State of Spark Streaming\""],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"markdown","source":["Next, use `LATERAL VIEW` to explode multiple columns at once, in this case, the columns `authors` and `categories`."],"metadata":{}},{"cell_type":"code","source":["%sql\nSELECT dates.publishedOn, title, author, category\nFROM DatabricksBlog\nLATERAL VIEW explode(authors) exploded_authors_view AS author\nLATERAL VIEW explode(categories) exploded_categories AS category\nWHERE title = \"Apache Spark 1.1: The State of Spark Streaming\"\nORDER BY author, category"],"metadata":{},"outputs":[],"execution_count":41},{"cell_type":"markdown","source":["## Exercise 1\n\nIdentify all the articles written or co-written by Michael Armbrust."],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n### Step 1\n\nStarting with the table `DatabricksBlog`, create a temporary view called `ArticlesByMichael` where:\n0. Michael Armbrust is the author\n0. The data set contains the column `title` (it may contain others)\n0. It contains only one record per article\n\n<img alt=\"Hint\" title=\"Hint\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.3em\" src=\"https://files.training.databricks.com/static/images/icon-light-bulb.svg\"/>&nbsp;**Hint:** See the Spark documentation, <a href=\"https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#module-pyspark.sql.functions\" target=\"_blank\">built-in functions</a>.  \n\n<img alt=\"Hint\" title=\"Hint\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.3em\" src=\"https://files.training.databricks.com/static/images/icon-light-bulb.svg\"/>&nbsp;**Hint:** Include the column `authors` in your view, to help you debug your solution."],"metadata":{}},{"cell_type":"code","source":["%sql\n-- TODO\n\nFILL_IN"],"metadata":{},"outputs":[],"execution_count":44},{"cell_type":"code","source":["# TEST - Run this cell to test your solution.\n\nresultsDF = spark.sql(\"select title from ArticlesByMichael order by title\")\ndbTest(\"SQL-L5-articlesByMichael-count\", 3, resultsDF.count())\n\nresults = [r[0] for r in resultsDF.collect()]\ndbTest(\"SQL-L5-articlesByMichael-0\", \"Exciting Performance Improvements on the Horizon for Spark SQL\", results[0])\ndbTest(\"SQL-L5-articlesByMichael-1\", \"Spark SQL Data Sources API: Unified Data Access for the Apache Spark Platform\", results[1])\ndbTest(\"SQL-L5-articlesByMichael-2\", \"Spark SQL: Manipulating Structured Data Using Apache Spark\", results[2])\n\nprint(\"Tests passed!\")"],"metadata":{},"outputs":[],"execution_count":45},{"cell_type":"markdown","source":["### Step 2\nShow the list of Michael Armbrust's articles."],"metadata":{}},{"cell_type":"code","source":["%sql\n-- TODO\n\nFILL_IN"],"metadata":{},"outputs":[],"execution_count":47},{"cell_type":"markdown","source":["## Exercise 2\n\nIdentify the complete set of categories used in the Databricks blog articles."],"metadata":{}},{"cell_type":"markdown","source":["### Step 1\n\nStarting with the table `DatabricksBlog`, create another view called `UniqueCategories` where:\n0. The data set contains the one column `category` (and no others)\n0. This list of categories should be unique"],"metadata":{}},{"cell_type":"code","source":["%sql\n-- TODO\n\nFILL_IN"],"metadata":{},"outputs":[],"execution_count":50},{"cell_type":"code","source":["# TEST - Run this cell to test your solution.\n\nresultsCount = spark.sql(\"SELECT category FROM UniqueCategories order by category\")\n\ndbTest(\"SQL-L5-uniqueCategories-count\", 12, resultsCount.count())\n\nresults = [r[0] for r in resultsCount.collect()]\ndbTest(\"SQL-L5-uniqueCategories-0\", \"Announcements\", results[0])\ndbTest(\"SQL-L5-uniqueCategories-1\", \"Apache Spark\", results[1])\ndbTest(\"SQL-L5-uniqueCategories-2\", \"Company Blog\", results[2])\n\ndbTest(\"SQL-L5-uniqueCategories-9\", \"Platform\", results[9])\ndbTest(\"SQL-L5-uniqueCategories-10\", \"Product\", results[10])\ndbTest(\"SQL-L5-uniqueCategories-11\", \"Streaming\", results[11])\n\nprint(\"Tests passed!\")"],"metadata":{},"outputs":[],"execution_count":51},{"cell_type":"markdown","source":["### Step 2\nShow the complete list of categories."],"metadata":{}},{"cell_type":"code","source":["%sql\n-- TODO\n\nFILL_IN"],"metadata":{},"outputs":[],"execution_count":53},{"cell_type":"markdown","source":["## Exercise 3\n\nCount how many times each category is referenced in the Databricks blog."],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n### Step 1\n\nStarting with the table `DatabricksBlog`, create a temporary view called `TotalArticlesByCategory` where:\n0. The new table contains two columns, `category` and `total`\n0. The `category` column is a single, distinct category (similar to the last exercise)\n0. The `total` column is the total number of articles in that category\n\n<img alt=\"Hint\" title=\"Hint\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.3em\" src=\"https://files.training.databricks.com/static/images/icon-light-bulb.svg\"/>&nbsp;**Hint:** You need either multiple views or a `LATERAL VIEW` to solve this.\n\n<img alt=\"Side Note\" title=\"Side Note\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.05em; transform:rotate(15deg)\" src=\"https://files.training.databricks.com/static/images/icon-note.webp\"/> Because articles can be tagged with multiple categories, the sum of the totals adds up to more than the total number of articles."],"metadata":{}},{"cell_type":"code","source":["%sql\n-- TODO\n\nFILL_IN"],"metadata":{},"outputs":[],"execution_count":56},{"cell_type":"code","source":["# TEST - Run this cell to test your solution.\n\nresultsDF = spark.sql(\"SELECT category, total FROM TotalArticlesByCategory ORDER BY category\")\ndbTest(\"SQL-L5-articlesByCategory-count\", 12, resultsDF.count())\n\nresults = [ (r[0]+\" w/\"+str(r[1])) for r in resultsDF.collect()]\n\ndbTest(\"SQL-L5-articlesByCategory-0\", \"Announcements w/72\", results[0])\ndbTest(\"SQL-L5-articlesByCategory-1\", \"Apache Spark w/132\", results[1])\ndbTest(\"SQL-L5-articlesByCategory-2\", \"Company Blog w/224\", results[2])\n\ndbTest(\"SQL-L5-articlesByCategory-9\", \"Platform w/4\", results[9])\ndbTest(\"SQL-L5-articlesByCategory-10\", \"Product w/83\", results[10])\ndbTest(\"SQL-L5-articlesByCategory-11\", \"Streaming w/21\", results[11])\n\nprint(\"Tests passed!\")"],"metadata":{},"outputs":[],"execution_count":57},{"cell_type":"markdown","source":["### Step 2\nDisplay the totals of each category, order by `category`."],"metadata":{}},{"cell_type":"code","source":["%sql\n-- TODO\n\nFILL_IN"],"metadata":{},"outputs":[],"execution_count":59},{"cell_type":"markdown","source":["## Summary\n\n* Spark SQL allows you to query and manipulate structured and semi-structured data\n* Spark SQL's built-in functions provide powerful primitives for querying complex schemas"],"metadata":{}},{"cell_type":"markdown","source":["## Review Questions\n**Q:** What is the syntax for accessing nested columns?  \n**A:** Use the dot notation: ```SELECT dates.publishedOn```\n\n**Q:** What is the syntax for accessing the first element in an array?  \n**A:** Use the [subscript] notation:  ```SELECT authors[0]```\n\n**Q:** What is the syntax for expanding an array into multiple rows?  \n**A:** Use the explode keyword, either:  \n```SELECT explode(authors) as Author``` or  \n```LATERAL VIEW explode(authors) exploded_authors_view AS author```"],"metadata":{}},{"cell_type":"markdown","source":["## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Classroom-Cleanup<br>\n\nRun the **`Classroom-Cleanup`** cell below to remove any artifacts created by this lesson."],"metadata":{}},{"cell_type":"code","source":["%run \"./Includes/Classroom-Cleanup\""],"metadata":{},"outputs":[],"execution_count":63},{"cell_type":"markdown","source":["## Next Steps\n\nStart the next lesson, [Querying Data Lakes with SQL]($./SSQL 06 - Data Lakes)."],"metadata":{}},{"cell_type":"markdown","source":["## Additional Topics & Resources\n\n* <a href=\"https://docs.databricks.com/spark/latest/spark-sql/index.html\" target=\"_blank\">Spark SQL Reference</a>\n* <a href=\"http://spark.apache.org/docs/latest/sql-programming-guide.html\" target=\"_blank\">Spark SQL, DataFrames and Datasets Guide</a>\n* <a href=\"https://stackoverflow.com/questions/36876959/sparksql-can-i-explode-two-different-variables-in-the-same-query\" target=\"_blank\">SparkSQL: Can I explode two different variables in the same query? (StackOverflow)</a>"],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n&copy; 2020 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{}}],"metadata":{"name":"SSQL 05 - Querying JSON","notebookId":2451692899067565},"nbformat":4,"nbformat_minor":0}
